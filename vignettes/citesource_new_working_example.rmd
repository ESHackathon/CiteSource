---
title: "New Source Analysis Across Screening Phases"

author: ""

date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{New Source Analysis Across Screening Phases}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 10,
  fig.height = 10,
  warning = FALSE
)
```
## About this vignette

In order to complete a reliable systematic search one must include multiple resources to ensure the inclusion of all relevant studies. The exact number of sources that are necessary for a thorough search can vary depending on the topic, type of review, etc. Along with the selection and search of traditional literature sources, other methods such as hand searching relevant journals, citation chasing/snowballing, searching websites, etc. can be used to minimize the risk of missing relevant studies. 

But how important is that extra database? How much return are you getting from the weeks worth of combing through websites? Did that open resource perform as well as (or better than) the one that your library/institution pays 500k/year for? How much time could you save if you had these answers? Wouldn't knowing the answers to these questions give us a better understanding of HOW to conduct our searches? Wouldn't it be great it we could speed up the process without impacting its quality, and better yet, improve our understanding while making the process faster?

These were some of the main questions that our team wanted to answer. The goal of this vignette (which we'd love your feedback on) is to show you how CiteSource can help you gather information on the ways sources and methods impact a review. The data in this vignette is based on a subset of data from an mock project. In this mock project, we'll be looking at searches used to find systematic reviews and meta-analyises on the health, environmental and economic impacts of wildfires. We'll walk through how CiteSource can import original search results, compare those information sources and methods, and determine how they contributed to the final review. 

If you have any questions, feedback, ideas, etc. about this vignette or others be sure to check out our [discussion board](https://github.com/ESHackathon/CiteSource/discussions/100) on github! 

## 1. Installation of packages and loading libraries

Use the following code to install CiteSource. Currently, CiteSource lives on GitHub, so you may need to first install the remotes package. This vignette also uses functions from the *ggplot2* and *dplyr* packages.

```{r, results = FALSE, message=FALSE}
#Install the remotes packages to enable installation from GitHub
#install.packages("remotes")
#library(remotes)

#Install CiteSource
#remotes::install_github("ESHackathon/CiteSource")

#Load the necessary libraries
library(CiteSource)
#library(dplyr)
```

## 2. Import Reference Files and Add Custom Metadata

Users can import multiple .ris or .bib files into CiteSource, which they can then label with three custom metadata fields: cite_source, cite_string, and cite_label. 

Using the cite_source field, the user can label individual files with source information such as database or platform. Beyond source information, users may also use the cite_source field to provide search results using various search methodologies. 

The second field, cite_label, can be used to apply yet another variable. This label was intended to be used in combination with the label cite_source, to track the inclusion or exclusion of citations from a specific source over the course of title/abstract and full text screening.

As a note, CiteSource does provide a third metadata field, cite_string, which can be used to specify another attribute or variable. For example, a use of cite_source and cite_string may be used to examine the unique and crossover citations that occur between databases, while simultaneously evaluating unique search string results. While it's possible to use cite_string, we have not fully integrated this third field into any of our tables and plots and it is not used in this vignette. As we continue to develop CiteSource and get feedback from users, we'll continue to update this and other vignettes.

### Indicate file location
```{r}
#Import citation files from a folder
citation_files <- list.files(path = file.path("../vignettes/new_stage_data"), pattern = "\\.ris", full.names = TRUE)

#Print citation_files to double check the order in which R imported the files.
citation_files
```


## 3. Read in citation files and add custom metadata

Prior to importing files into CiteSource, it is recommended that users import raw .ris/.bib files into a citation management software such as EndNote or Zotero and combine multiple citation files from each individual source. This can reduce complication and assist with applying metadata. Features such as EndNote's "find reference updates" can also ensure that citations are more complete by filling in missing metadata fields.

In this example, we read in the citation files and tag the citation files with the resource they came from using the cite_source field. The two citation files labeled NA represent the file from included papers after title/abstract screening and the file of the included papers after full-text screening and therefore are not assigned a source. The cite_label tag is being used to tag files with "search" (the initial search results), "screened" (included papers after TI/AB screening), and "final" (papers included after full-text screening).


```{r}
# Import citation files from folder
citation_files <- list.files(path = "new_stage_data", pattern = "\\.ris", full.names = TRUE)

# Print list of citation files to console
citation_files

# Set the path to the directory containing the citation files
file_path <- "../vignettes/new_stage_data/"

metadata_tbl <- tibble::tribble(
  ~files,                ~cite_sources,        ~cite_labels, 
   "wos_278.ris",        "WoS",                "search",    
   "medline_84.ris",     "Medline",            "search",   
   "econlit_3.ris",      "EconLit",            "search",    
   "Dimensions_246.ris", "Dimensions",         "search",   
   "lens_343.ris",       "Lens.org",           "search",    
   "envindex_100.ris",   "Environment Index",  "search",  
   "screened_128.ris",   NA,                   "screened",  
   "final_24.ris",       NA,                   "final"
) %>% 

dplyr::mutate(files = paste0(file_path, files))
citations <- read_citations(metadata = metadata_tbl)
```


## 4. Deduplication & Identifying Crossover Records

CiteSource allows users to merge duplicate records, while maintaining information in the cite_source, cite_label,and cite_string fields. 

Note that duplicates are assumed to published in the same source, so pre-prints and similar results will not be identified as duplicates.


```{r}
unique_citations <- dedup_citations(citations)

# Count number of unique and non-unique citations from different sources and labels
n_unique <- count_unique(unique_citations)

# Create dataframe indicating occurrence of records across sources
source_comparison <- compare_sources(unique_citations, comp_type = "sources")

# initial upload/post internal deduplication table creation
initial_counts<-record_counts(unique_citations, citations, "cite_source")
record_counts_table(initial_counts)

```


## 5. Analyzing Sources & Methods

When teams are selecting databases for inclusion in a review it can be extremely difficult to determine the best resources and determine the return on investment in terms of the time it takes to apply searches. This is especially true in fields where research relies on cross-disciplinary resources. By tracking and reporting where/how each citation was found, the evidence synthesis community could in turn track the utility of various databases/platforms and identify the most relevant resources as it relates to their research topic. This idea can be extended to search string comparison as well as various search strategies and methodologies.

### Plot overlap as a heatmap matrix
CiteSource performs citation analysis and deduplication within each source file, prior to comparing sources across source files. This heatmap shows the number of citations unique to each source at the top of the source's column. The heatmap also provides a count of citations that were found at the intersection of each source. 

In this case, you can see that the Lens.org shows 340 records, while the initial .ris file contained 343 citations. This means that CiteSource identified duplicate references within that citation list. The 340 remaining citations are attributed to this source. Looking at the source Medline, we can see that  CiteSource did not find any duplicate citations within this source as both counts read 84.

```{r}
my_heatmap <- plot_source_overlap_heatmap(source_comparison)

my_heatmap
```

### Plot overlap as a heatmap matrix as percentage
The following heatmap provides an overview of the overlapping citations by percent of each source's count. For example the Environment Index source contains 100 citations. Of those 100 we can see on the previous heatmap that 82 of these citations were also in Lens.org, which represents 82% of the citations from Environment Index. On the other hand the same 82 citations only represent 24% of the total citations in Lens.org. 
```{r}
my_heatmap_percent <- plot_source_overlap_heatmap(source_comparison, plot_type = "percentages")

my_heatmap_percent
```

### Plot overlap as an upset plot

Another way of looking at overlap of sources is an upset plot. With this visualizations, we can also see the number of unique contributions of any given source. In this example, we can see that the search in EconLit only had three results, but of those, two were unique and not found in any other source. This plot also tells us that Lens.org and Web of Science both contributed by far the most unique records and that Dimensions and Lens.org show the greatest overlap, with 63 records shared between them. 

```{r}
my_upset_plot <- plot_source_overlap_upset(source_comparison, decreasing = c(TRUE, TRUE))

my_upset_plot
```

## 6. Analyzing records after screening

Once the title and abstract screening has been completed or once the final papers have been selected, users can analyze the contributions of each source or search method to these screening phases to better understand their impact on the review. By using the "cite_source" data along with the "cite_label" data, users can analyze the number of overlapping/unique records from each source or method. This plot shows us the unique records contributed to each review stage (i.e., overall search, included after title/abstract screening, and final included studies). 

### Assessing contribution of sources by review stage
```{r}
my_contributions <- plot_contributions(n_unique,
  center = TRUE,
  bar_order = c("search", "screened", "final")
)

my_contributions
```

### Analyzing Precision/Sensitivity 

In addition to the above visualizations, it may be useful to export tables for additional analysis. Presenting data in the form of a search summary table can provide an overview of each source's impact as well as precision and sensitivity (see [Bethel et al. 2021](https://doi.org/10.5195/jmla.2021.809) for more about search summary tables). 

```{r}
calculated_counts<-calculate_record_counts(unique_citations, citations, n_unique, "cite_source")
record_summary_table(calculated_counts)
```

```{r}
phase_counts<-calculate_phase_count(unique_citations, citations, "cite_source")
precision_sensitivity_table(phase_counts)
```

### Creating a Citation Record Table

Another useful table that can be exported as a .csv is the record-level table. This table allows users to quickly identify which individual citations in the screened and/or final records were present/absent from each source. The source tag is the default (include = "sources"), but can be replaced or expanded with 'labels' and/or 'strings'
```{r}
unique_citations %>%
  dplyr::filter(stringr::str_detect(cite_label, "final")) %>%
  record_level_table(return = "DT")
```
  
## 7. Exporting for further analysis

We may want to export our deduplicated set of results (or any of our dataframes) for further analysis or to save them in a convenient format for subsequent use. CiteSource offers a set of export functions called `export_csv`, `export_ris` and `export_bib` that will save dataframes as a .csv file, .ris file or .bib file, respectively. 

You can then reimport exported files to pick up a project or analysis without having to start from scratch, or after making manual adjustments (such as adding missing abstract data) to a file. 

**Generate a .csv file.** The separate argument can be used to create separate columns for cite_source, cite_label or cite_string to facilitate analysis.

```{r}
#export_csv(unique_citations, filename = "citesource_working_example.csv", separate = "cite_source")
```

**Generate a .ris file and indicate custom field location for cite_source, cite_label or cite_string.** In this example, we'll be using EndNote, so we put cite_sources in the DB field, which will appear as the *Name of Database* field in EndNote and cite_labels into C5, which will appear as the *Custom 5* metadata field in EndNote.

```{r}
#export_ris(unique_citations, filename = "citesource_working_example.ris", source_field = "DB", label_field = "C5")
```

**Generate a bibtex file and include data from cite_source, cite_label or cite_string.**

```{r}
#export_bib(unique_citations, filename = "citesource_working_example.bib", include = c("sources", "labels", "strings"))
```

In order to reimport a .csv or a .ris you can use the following. Here is an example of how you would reimport the file if it were on your desktop

```{r}
#citesource_working_example <-reimport_csv("citesource_working_example.csv")

#citesource_working_example <-reimport_ris("citesource_working_example.ris")

```
